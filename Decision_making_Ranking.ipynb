{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision making_Ranking.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barsukpolina/Messages-format-and-user-trust-in-chatbots/blob/main/Decision_making_Ranking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAPxsMEKErtJ"
      },
      "source": [
        "### ДЗ №1 Ранжирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPZs7bXeEhIU"
      },
      "source": [
        "1. **Нужно выбрать любой алгоритм ранжирования**\n",
        "2. Разобраться с общим принципом работы алгоритма и найти его реализацию на R или Python\n",
        "3. Применить алгоритм к данным, оценить качество ранжирования\n",
        "4. Выбрать один из запросов (query) из тестовой выборки, указать, в каком порядке нужно расположить документы для него согласно построенной модели.\n",
        "5. Написать отчет. В отчете должно быть \n",
        "краткое описание алгоритма (можно без формул, но должен быть указан тип pointwise/pairwise/listwise, с какими данными работает (только бинарные, только определенной структуры, все равно), общий принцип работы);\n",
        "построенная модель;\n",
        "оценка качества модели (NDCG/MAP/...);\n",
        "пример ранжирования для примера из тестовой выборки (в каком порядке расположить документы)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_NjIjoxHj_s"
      },
      "source": [
        "Алгоритм ранжирования - **Rankwise** (относится к типу pairwise).\n",
        "\n",
        "Тут используется pytorch, чтобы реализовать нейронные сети."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb1XgFN4MJ6o"
      },
      "source": [
        "**Принцип работы алгоритма Rankwise**:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhTX144IL0DJ"
      },
      "source": [
        "* n_feature: int, features numble\n",
        "* h1_units: int, the unit numbers of hidden layer1\n",
        "* h2_units: int, the unit numbers of hidden layer2\n",
        "* epoch: int, iteration times\n",
        "* learning_rate: float, learning rate\n",
        "* plot: boolean, whether plot the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvfcD-qyJLY0"
      },
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import argparse\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcVOE7EOJRPJ"
      },
      "source": [
        "def dcg(scores):\n",
        "    \"\"\"\n",
        "    compute the DCG value based on the given score\n",
        "    :param scores: a score list of documents\n",
        "    :return v: DCG value\n",
        "    \"\"\"\n",
        "    v = 0\n",
        "    for i in range(len(scores)):\n",
        "        v += (np.power(2, scores[i]) - 1) / np.log2(i+2)  # i+2 is because i starts from 0\n",
        "    return v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUWeiGHtJ51C"
      },
      "source": [
        "def idcg(scores):\n",
        "    \"\"\"\n",
        "    compute the IDCG value (best dcg value) based on the given score\n",
        "    :param scores: a score list of documents\n",
        "    :return:  IDCG value\n",
        "    \"\"\"\n",
        "    best_scores = sorted(scores)[::-1]\n",
        "    return dcg(best_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wjl4QGnJ7rb"
      },
      "source": [
        "def ndcg(scores):\n",
        "    \"\"\"\n",
        "    compute the NDCG value based on the given score\n",
        "    :param scores: a score list of documents\n",
        "    :return:  NDCG value\n",
        "    \"\"\"\n",
        "    return dcg(scores)/idcg(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h-e6F9tJ-UC"
      },
      "source": [
        "def delta_ndcg(scores, p, q):\n",
        "    \"\"\"\n",
        "    swap the i-th and j-th doucment, compute the absolute value of NDCG delta\n",
        "    :param scores: a score list of documents\n",
        "    :param p, q: the swap positions of documents\n",
        "    :return: the absolute value of NDCG delta\n",
        "    \"\"\"\n",
        "    s2 = scores.copy()  # new score list\n",
        "    s2[p], s2[q] = s2[q], s2[p]  # swap\n",
        "    return abs(ndcg(s2) - ndcg(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEp_cGfTKBUH"
      },
      "source": [
        "def ndcg_k(scores, k):\n",
        "    scores_k = scores[:k]\n",
        "    fenzi = dcg(scores_k)\n",
        "    fenmu = dcg(sorted(scores)[::-1][:k])\n",
        "    return fenzi/fenmu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU0uwvJBKENG"
      },
      "source": [
        "def group_by(data, qid_index):\n",
        "    \"\"\"\n",
        "    group documents by query-id\n",
        "    :param data: input_data which contains multiple query and corresponding documents\n",
        "    :param qid_index: the column num where qid locates in input data\n",
        "    :return: a dict group by qid\n",
        "    \"\"\"\n",
        "    qid_doc_map = {}\n",
        "    idx = 0\n",
        "    for record in data:\n",
        "        qid_doc_map.setdefault(record[qid_index], [])\n",
        "        qid_doc_map[record[qid_index]].append(idx)\n",
        "        idx += 1\n",
        "    return qid_doc_map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU_ISkqbKF3A"
      },
      "source": [
        "def get_pairs(scores):\n",
        "    \"\"\"\n",
        "    compute the ordered pairs whose firth doc has a higher value than second one.\n",
        "    :param scores: given score list of documents for a particular query\n",
        "    :return: ordered pairs.  List of tuple, like [(1,2), (2,3), (1,3)]\n",
        "    \"\"\"\n",
        "    pairs = []\n",
        "    for i in range(len(scores)):\n",
        "        for j in range(len(scores)):\n",
        "            if scores[i] > scores[j]:\n",
        "                pairs.append((i, j))\n",
        "    return pairs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQJKCsEqKIG8"
      },
      "source": [
        "\n",
        "def split_pairs(order_pairs, true_scores):\n",
        "    \"\"\"\n",
        "    split the pairs into two list, named relevant_doc and irrelevant_doc.\n",
        "    relevant_doc[i] is prior to irrelevant_doc[i]\n",
        "    :param order_pairs: ordered pairs of all queries\n",
        "    :param ture_scores: scores of docs for each query\n",
        "    :return: relevant_doc and irrelevant_doc\n",
        "    \"\"\"\n",
        "    relevant_doc = []\n",
        "    irrelevant_doc = []\n",
        "    doc_idx_base = 0\n",
        "    query_num = len(order_pairs)\n",
        "    for i in range(query_num):\n",
        "        pair_num = len(order_pairs[i])\n",
        "        docs_num = len(true_scores[i])\n",
        "        for j in range(pair_num):\n",
        "            d1, d2 = order_pairs[i][j]\n",
        "            d1 += doc_idx_base\n",
        "            d2 += doc_idx_base\n",
        "            relevant_doc.append(d1)\n",
        "            irrelevant_doc.append(d2)\n",
        "        doc_idx_base += docs_num\n",
        "    return relevant_doc, irrelevant_doc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhnHnFuxKNUg"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    construct the RankNet\n",
        "    \"\"\"\n",
        "    def __init__(self, n_feature, h1_units, h2_units):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.model = torch.nn.Sequential(\n",
        "            # h_1\n",
        "            torch.nn.Linear(n_feature, h1_units),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.ReLU(),\n",
        "            # h_2\n",
        "            torch.nn.Linear(h1_units, h2_units),\n",
        "            torch.nn.Dropout(0.5),\n",
        "            torch.nn.ReLU(),\n",
        "            # output\n",
        "            torch.nn.Linear(h2_units, 1),\n",
        "        )\n",
        "        self.output_sig = torch.nn.Sigmoid()\n",
        "\n",
        "    def forward(self, input_1, input_2):\n",
        "        s1 = self.model(input_1)\n",
        "        s2 = self.model(input_2)\n",
        "        out = self.output_sig(s1-s2)\n",
        "        return out\n",
        "\n",
        "    def predict(self, input_):\n",
        "        s = self.model(input_)\n",
        "        n = s.data.numpy()[0]\n",
        "        return n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac_GqnINEga3"
      },
      "source": [
        "class RankNet():\n",
        "    \"\"\"\n",
        "    user interface\n",
        "    \"\"\"\n",
        "    def __init__(self, n_feature, h1_units, h2_units, epoch, learning_rate, plot=True):\n",
        "        self.n_feature = n_feature\n",
        "        self.h1_units = h1_units\n",
        "        self.h2_units = h2_units\n",
        "        self.model = Model(n_feature, h1_units, h2_units)\n",
        "        self.epoch = epoch\n",
        "        self.plot = plot\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def decay_learning_rate(self, optimizer, epoch, decay_rate):\n",
        "        if (epoch+1) % 10 == 0:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = param_group['lr'] * decay_rate\n",
        "\n",
        "    def fit(self, training_data):\n",
        "        \"\"\"\n",
        "        train the RankNet based on training data.\n",
        "        After training, save the parameters of RankNet, named 'parameters.pkl'\n",
        "        :param training_data:\n",
        "        \"\"\"\n",
        "\n",
        "        net = self.model\n",
        "        qid_doc_map = group_by(training_data, 1)\n",
        "        query_idx = qid_doc_map.keys()\n",
        "        # true_scores is a matrix, different rows represent different queries\n",
        "        true_scores = [training_data[qid_doc_map[qid], 0] for qid in query_idx]\n",
        "\n",
        "        order_paris = []\n",
        "        for scores in true_scores:\n",
        "            order_paris.append(get_pairs(scores))\n",
        "\n",
        "        relevant_doc, irrelevant_doc = split_pairs(order_paris ,true_scores)\n",
        "        relevant_doc = training_data[relevant_doc]\n",
        "        irrelevant_doc = training_data[irrelevant_doc]\n",
        "\n",
        "        X1 = relevant_doc[:, 2:]\n",
        "        X2 = irrelevant_doc[:, 2:]\n",
        "        y = np.ones((X1.shape[0], 1))\n",
        "\n",
        "        # training......\n",
        "        X1 = torch.Tensor(X1)\n",
        "        X2 = torch.Tensor(X2)\n",
        "        y = torch.Tensor(y)\n",
        "\n",
        "        optimizer = torch.optim.Adam(net.parameters(), lr=self.learning_rate)\n",
        "\n",
        "        loss_fun = torch.nn.BCELoss()\n",
        "\n",
        "        loss_list = []\n",
        "\n",
        "        if self.plot:\n",
        "            plt.ion()\n",
        "\n",
        "        print('Traning………………\\n')\n",
        "        for i in range(self.epoch):\n",
        "            self.decay_learning_rate(optimizer, i, 0.95)\n",
        "\n",
        "            net.zero_grad()\n",
        "            y_pred = net(X1, X2)\n",
        "            loss = loss_fun(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_list.append(loss.data.numpy())\n",
        "            if self.plot:\n",
        "                    plt.cla()\n",
        "                    plt.plot(range(i+1), loss_list, 'r-', lw=5)\n",
        "                    plt.xlabel('Epoch')\n",
        "                    plt.ylabel('Loss')\n",
        "                    plt.pause(1)\n",
        "            if i % 10 == 0:\n",
        "                print('Epoch:{}, loss : {}'.format(i, loss.item()))\n",
        "\n",
        "\n",
        "        if self.plot:\n",
        "            plt.ioff()\n",
        "            plt.show()\n",
        "\n",
        "        # save model parameters\n",
        "        torch.save(net.state_dict(), 'parameters.pkl')\n",
        "\n",
        "    def validate(self, test_data, k):\n",
        "        \"\"\"\n",
        "        compute the average NDCG@k for the given test data.\n",
        "        :param test_data: test data\n",
        "        :param k: used to compute NDCG@k\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        # load model parameters\n",
        "        net = Model(self.n_feature, self.h1_units, self.h2_units)\n",
        "        net.load_state_dict(torch.load('parameters.pkl'))\n",
        "\n",
        "        qid_doc_map = group_by(test_data, 1)\n",
        "        #print(net.predict(qid_doc_map.get(19737.0)))\n",
        "        query_idx = qid_doc_map.keys()\n",
        "        ndcg_k_list = []\n",
        "\n",
        "        for q in query_idx:\n",
        "            true_scores = test_data[qid_doc_map[q], 0]\n",
        "            if sum(true_scores) == 0:\n",
        "                continue\n",
        "            docs = test_data[qid_doc_map[q]]\n",
        "            X_test = docs[:, 2:]\n",
        "\n",
        "            pred_scores = [net.predict(torch.Tensor(test_x).data) for test_x in X_test]\n",
        "            pred_rank = np.argsort(pred_scores)[::-1]\n",
        "            pred_rank_score = true_scores[pred_rank]\n",
        "            ndcg_val = ndcg_k(pred_rank_score, k)\n",
        "            ndcg_k_list.append(ndcg_val)\n",
        "        print(\"Average NDCG@{} is {}\".format(k, np.mean(ndcg_k_list)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzFNhbeMf8Im"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLpEodGaVJvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7156d5f-0923-413d-9a5f-e461065bb324"
      },
      "source": [
        "n = np.load('test.npy')\n",
        "print(n[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00000e+00 1.82190e+04 4.95900e-03 0.00000e+00 2.50000e-01 5.00000e-01\n",
            " 6.62300e-03 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
            " 4.97100e-03 0.00000e+00 2.59494e-01 5.21932e-01 6.63900e-03 8.96000e-04\n",
            " 7.14286e-01 7.00000e-01 0.00000e+00 1.09300e-03 2.29604e-01 2.37068e-01\n",
            " 2.00021e-01 6.33180e-02 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
            " 3.10838e-01 3.37990e-02 1.39800e-03 2.59760e-02 5.76917e-01 3.63020e-02\n",
            " 1.12900e-03 2.26420e-02 1.41223e-01 2.12802e-01 1.68053e-01 6.95560e-02\n",
            " 3.33333e-01 0.00000e+00 0.00000e+00 1.92550e-02 4.21053e-01 0.00000e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VLSl8_daqaF"
      },
      "source": [
        "grouped = group_by(n,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umoEFXKUi8MA"
      },
      "source": [
        "19737.0: [2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330],"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0zDntDGjbDK",
        "outputId": "68bb9e50-325b-4b82-87ae-6e788789ce76"
      },
      "source": [
        "grouped.get(19737.0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "hhI_10AdKT4F",
        "outputId": "2be1a505-e1d6-4eec-be9d-301a6091fdc0"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    print('Load training data...')\n",
        "    training_data = np.load('train.npy')\n",
        "    print('Load done.\\n\\n')\n",
        "\n",
        "    model1 = RankNet(46, 512, 256, 20, 0.01, False)\n",
        "    model1.fit(training_data)\n",
        "\n",
        "    print('Validate...')\n",
        "    test_data = np.load('test.npy')\n",
        "    model1.validate(test_data, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load training data...\n",
            "Load done.\n",
            "\n",
            "\n",
            "Traning………………\n",
            "\n",
            "Epoch:0, loss : 0.6910508275032043\n",
            "Epoch:10, loss : 0.43268004059791565\n",
            "Validate...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-c37247fdc657>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Validate...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-62-4da87576c5ee>\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(self, test_data, k)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mqid_doc_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup_by\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqid_doc_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m19737.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mquery_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqid_doc_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mndcg_k_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-c2819ecf5662>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUq92rl_K6mc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}